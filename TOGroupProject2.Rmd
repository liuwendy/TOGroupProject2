---
title: "TOGroupProject2"
author: "Wendy Liu, Mack Khoo, Nelvin Vincent, TJ Striblen, & Nihal Kurki"
date: "2022-10-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem
Dataset from: https://www.kaggle.com/datasets/sakshigoyal7/credit-card-customers
This dataset consists of 10,000 customers mentioning their age, salary, marital_status, credit card limit, credit card category, etc.(nearly 18 features). The dataset only consists of 16.07% of customers who have churned.

Business Problem: A business manager of a consumer credit card bank is facing the problem of customer attrition. They want to analyze the data to find out the reason behind this and leverage the same to predict customers who are likely to drop off. They also want to predict customer churn from the dataset and gain some insights on how the bank can reduce the customers who have churned.

Our group wants to predict which credit card customers are more likely to churn. Churn prediction means detecting which customers are likely to leave a service or to cancel a subscription to a service. It is a critical prediction for many businesses because acquiring new clients often costs more than retaining existing ones.

## Description of Data
* CLIENTNUM: Client number; unique identifier for a customer holding the account.
* Attrition_Flag: Customer activity; 0 if account is closed.
* Customer_Age: Customer age (in years).
* Gender
* Dependent_count: Number of dependents.
* Education_Level: Educational attainment of the account holder.
* Marital_Status
* Income_Category: Annual Income range of the account holder.
* Card_Category: Type of card of the account.
* Months_on_book: Period of relationship with the bank (in months)
* Total_Relationship_Count: Total number of products held by the customer.
* Months_Inactive_12_mon: Number of months inactive for the past 12 months (in months).
* Contacts_Count_12_mon: Number of contacts in the last 12 months.
* Credit_Limit: The credit limit of the credit card.
* Total_Revolving_Bal: The total revolving balance in the credit card.
* Avg_Open_To_Buy: The difference between the credit limit assigned to a cardholder account and the * present balance on the account (average of the last 12 months).
* Total_Amt_Chng_Q4_Q1: Change in transaction amount (Q4 over Q1).
* Total_Trans_Amt: The total transaction amount (last 12 months).
* Total_Trans_Ct: The total transaction count (last 12 months).
* Total_Ct_Chng_Q4_Q1: The change in transaction count (Q4 over Q1).
* Avg_Utilization_Ratio: How much a customer currently owes divided by the credit limit (in %).

## Downloading and Prepping Data

To clean up the data we wanted to first make multiple variables that are either unavailable to us prior to looking at customer attrition (such as the naive bayes classifier) or variables that have no use in predicting attrition (the client number). The data was able to factor the non-numerical variables such as "Attrition_Flag", "Education_Level", "Marital_Status", "Income_Category", & "Card_Category" while the rest remained numeric and not as a factor. One thing we found interesting when exploring the dataset is that the attrited customer percentage is only around 16% which will make it harder to predict, but not at all impossible. Of course we will also need to normalize many of the numerical variables as Credit Limit and Dependent Count are on very different scales. And after an initial logistic regression model, we found that dependent count, income, and months with the bank or months of inactivity hold high correlations to credit card churn.

## Data Cleaning
```{r}
credit <- read.csv("BankChurners.csv", stringsAsFactors = TRUE)

credit$CLIENTNUM <- NULL
credit$Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1 <- NULL
credit$Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2 <- NULL

# Ordinal variable
credit$Income_Category <- factor(credit$Income_Category, levels = c("Less than $40K", "$40K - $60K", "$60K - $80K", "$80K - $120K", "$120K +", "Unknown"), labels = c(0, 1, 2, 3, 4, 5))

credit$Card_Category <- factor(credit$Card_Category, levels = c("Blue", "Silver", "Gold", "Platinum"), labels = c(0, 1, 2, 3))

credit$Education_Level <- factor(credit$Education_Level, levels = c("Uneducated", "High School", "College", "Graduate", "Post-Graduate", "Doctorate", "Unknown"), labels = c(0, 1, 2, 3, 4, 5, 6))

# Nominal variable
credit$Gender <- factor(credit$Gender, levels = c("M", "F"), labels = c(0, 1))

credit$Attrition_Flag <- factor(credit$Attrition_Flag, levels = c("Existing Customer", "Attrited Customer"), labels = c(0, 1))

credit$Marital_Status <- factor(credit$Marital_Status, levels = c("Single", "Married", "Divorced", "Unknown"), labels = c(0, 1, 2, 3))

summary(credit)
str(credit)

```

## Normalize the data
```{r}
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

creditmm <- as.data.frame(model.matrix(~.-1,credit))
set.seed(12345)
credit_random <- creditmm[sample(nrow(creditmm)),]

credit_norm <- as.data.frame(lapply(credit_random, normalize))
credit_norm$Attrition_Flag0 <- NULL
```


## Splitting train and test

```{r}
test_set <- sample(1:nrow(credit_norm), nrow(credit_norm)/2)

# Create a train set and test set
#First the predictors - all columns except the Attrition_Flag1 column

credit_train <- credit_norm[-test_set,]
credit_test <- credit_norm[test_set,]

#credit_train <- credit_norm[-test_set, -match("Attrition_Flag1",names(credit_norm))]
#credit_test <- credit_norm[test_set, -match("Attrition_Flag1",names(credit_norm))]

#Now the response (aka Labels) - only the Attrition_Flag1 column
#credit_train_labels <- credit_norm[-test_set, "Attrition_Flag1"]
#credit_test_labels <- credit_norm[test_set, "Attrition_Flag1"]
```

## Regression Train

```{r}
library(caret)
log_ctrl <- trainControl(method="cv", number=10)
log_train <- train(as.factor(Attrition_Flag1) ~ .+
                      Marital_Status1*Total_Trans_Ct + 
                      Total_Relationship_Count*Contacts_Count_12_mon +
                      Total_Trans_Amt*Total_Trans_Ct, 
            data = credit_train, method = "glm", 
            metric = "Kappa",
            trControl = log_ctrl,
            preProcess = c("center","scale")
            )
log_train
log_pred <-predict(log_train, credit_test)
```

## KNN Train

```{r}
library(caret)

knn_ctrl <- trainControl(method = "cv", number = 10)
knn_grid <- expand.grid(k = c(1, 5, 7, 9, 10, 15, 20))

knn_train <- train(as.factor(Attrition_Flag1) ~ ., data = credit_train, method = "knn",
           metric = "Kappa",
           trControl = knn_ctrl,
           preProcess = c("center","scale"), 
           tuneLength = 20,
           tuneGrid = knn_grid
           )

knn_train
knn_pred <-predict(knn_train, credit_test)
```

## ANN Train
```{r}
#We are using the cv method of resampling and we will be doing this 10 times for the training data
ann_ctrl <- trainControl(method = "cv", number = 10)
#Then using expand.grid to get all combinations
ann_grid <- expand.grid(.size = c(1, 5, 7, 9, 10, 15, 20),
                        .decay = c(0, 0.01, .1))
#We have set up for size for the number of units in the layer, and decay to prevent overfitting
#We are now training this on the Attrition Flag data from the credit_train data using a neural network model, using Kappa values for optimal model selection. We are using the control set and the tuning grid 1 we created earlier
ann_train <- train(as.factor(Attrition_Flag1) ~ ., data = credit_train, method = "nnet",
          metric = "Kappa",
          trControl = ann_ctrl,
          tuneGrid = ann_grid)

ann_train

ann_pred <- predict(ann_train, credit_test)
```

## SVM Train

```{r}
svm_control <- trainControl(method = "cv", number = 10)
svm_grid <- expand.grid(C=c(1, 5, 7, 9, 10, 15, 20))

svm_train <- train(as.factor(Attrition_Flag1) ~ ., 
                data = credit_train,
                method = "svmLinear",
                preProcess = c("center", "scale"),
                trControl = svm_control,
                metric = "Kappa",
                tuneGrid = svm_grid)
svm_train
svm_pred <-predict(svm_train, credit_test)
```

## Decision Tree Train

```{r}
library(caret)
dt_ctrl <- trainControl(method = "cv", number = 10,
                        selectionFunction = "oneSE")

dt_grid <- expand.grid(.model = "tree",
                       .trials = c(1, 5, 10, 15, 20, 25, 30, 35),
                       .winnow = "FALSE")

dt_train <- train(as.factor(Attrition_Flag1) ~ ., data = credit_train, method = "C5.0",
                  metric = "Kappa",
                  trControl = dt_ctrl,
                  tuneGrid = dt_grid)

dt_train
dt_pred <- predict(dt_train, credit_test)

#dt_train_pred <- predict(dt_train, credit_test)
#table(dt_train_pred, credit_norm$Attrition_Flag1)

#confusionMatrix(as.factor(credit_norm$Attrition_Flag1), dt_train_pred)
```

## Random Forest Train

```{r}
ranger_ctrl <- trainControl(method = "cv", number = 10)
ranger_grid <- expand.grid( mtry = c(2, 3, 4),
                             min.node.size = c(2, 4, 10),
                             splitrule = c('extratrees'))

ranger_train <- train(as.factor(Attrition_Flag1) ~ ., 
                  data = credit_train,
                  trControl = ranger_ctrl,
                  preProcess = c("center", "scale"),
                  metric = "Kappa",
                  method = "ranger",
                  tuneGrid = ranger_grid)

ranger_train
ranger_pred <-predict(ranger_train, credit_test)
```


## Single Data Frame
```{r}
all <- data.frame(log_pred, knn_pred, ann_pred, svm_pred, dt_pred, ranger_pred, credit_test$Attrition_Flag1)
```

## Error
```{r}
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2)
```


## Stacked Model
```{r}
test_set1 <- sample(1:nrow(all), round(nrow(all)*.3))

credit_train1 <- all[-test_set1, ]
credit_test1 <- all[test_set1, ]

library(C50)
stacked_model <- C5.0(as.factor(credit_test.Attrition_Flag1) ~ ., data=credit_train1, costs = error_cost)
plot(stacked_model)

stacked_pred <- predict(stacked_model, credit_test1)

library(gmodels)
library(caret)

CrossTable(credit_test1$credit_test.Attrition_Flag1, stacked_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual yyes', 'predicted yyes'))
confusionMatrix(as.factor(stacked_pred), as.factor(credit_test1$credit_test.Attrition_Flag1), positive = "1")
```
